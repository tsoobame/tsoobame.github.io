{"pageProps":{"post":{"title":"Understanding data loader","date":"2020-07-19","description":"Create a basic dataloader to understand this great library","thumbnailUrl":"/images/data-loader.jpeg","tags":["javascript"],"filePath":"data-loader.mdx","slug":"data-loader","mdxSource":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h1: \"h1\",\n    p: \"p\",\n    h2: \"h2\",\n    pre: \"pre\",\n    code: \"code\",\n    h3: \"h3\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.h1, {\n      children: \"Understanding the Dataloader\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Dataloader is one of the packages I find more useful and smart from the ones I have in my toolbox.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I am going to set up a obvious naive example and follow the process to build a simple dataloader to understand its beauty and how useful it is.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"About the project\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We are going to create a view and api over a social network. Our users relations are:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"User 1 friend of [ 2, 3 ]\\nUser 2 friend of [ 1, 3 ]\\nUser 3 friend of [ 1, 2, 4 ]\\nUser 4 friend of [ 3, 5 ]\\nUser 5 friend of [ 4 ]\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The view can show the relation between users and their friends. We can show N levels of their friendship. We are not goint to look much at it in this post.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Users data can be found here.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The only dependency will be express.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Initial Setup\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"datasource.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The datasource allows us to retrieve one or multiple users by id. Contract is not random, it is already based on the real dataloader so there will be minimal changes over the course of the post. Data is defined in a file within the project. Code is pretty simple:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"const users = require(\\\"./users.json\\\");\\n\\nconst getUsersFromFile = (ids) =>\\n  ids.map((id) => users.find((u) => u.id === id));\\n\\nconst sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));\\n\\nasync function loadMany(ids) {\\n  console.log(`GET /users?ids=${ids}`);\\n\\n  await sleep(100);\\n  return getUsersFromFile(ids);\\n}\\n\\nasync function load(id) {\\n  const results = await loadMany([id]);\\n  return results[0];\\n}\\n\\nmodule.exports = {\\n  load,\\n  loadMany,\\n};\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The only interesting method is loadMany. We will print the requests to the simulated service so we can check the console. There will be a delay to resolve the promise, so we can simulate better and understand why dataloader is so good.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A very important requirement is that data needs to be returned to the caller in the right order and all elements need to be returned (same length of ids and results arrays). This will be clear when we put in place the dataloader.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"resolver.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Resolver will use the datasource received by parameter to load friendship data about users. It can receive the levels of friends we want to get, so it will use a recursive approach to load friends of friends until all levels are fetched.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"async function getFriends(datasource, user, levels) {\\n  if (levels == 0) {\\n    return { id: user.id, name: user.name };\\n  }\\n\\n  const friends = await datasource.loadMany(user.friends);\\n\\n  return {\\n    ...user,\\n    friends: await Promise.all(\\n      friends.map((f) => getFriends(datasource, f, levels - 1))\\n    ),\\n  };\\n}\\n\\nasync function getUserWithFriends(datasource, id, levels = 1) {\\n  const user = await datasource.load(id);\\n  return getFriends(datasource, user, levels);\\n}\\n\\nmodule.exports = { getUserWithFriends };\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"It uses a brute force approach on purpose. The code is simple but far away from being optimal. In one method it looks obvious, but sometimes, when we are building graphql or similar apis, or complex workflows we might be doing exactly this kind of brute force requests.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"view.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Nothing advanced. Just render users friends in a nested way.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"function render(user) {\\n  return `<div style=\\\"padding-left: 12px;background-color:#def\\\"> ${user.name} ${\\n    user.friends ? user.friends.map((u) => render(u)).join(\\\"\\\") : \\\"\\\"\\n  } </div>`;\\n}\\n\\nmodule.exports = {\\n  render,\\n};\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"server.js\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"const express = require(\\\"express\\\");\\nconst PORT = 3000;\\nconst app = express();\\n\\nconst datasource = require(\\\"./datasource\\\");\\nconst resolver = require(\\\"./resolver\\\");\\nconst view = require(\\\"./view\\\");\\n\\napp.get(`/user-with-friends/:id`, async (req, res) => {\\n  const id = req.params.id;\\n  const levels = req.query.levels || 1;\\n\\n  const user = await resolver.getUserWithFriends(datasource, id, levels);\\n\\n  res.send(view.render(user));\\n});\\n\\napp.listen(PORT, () => console.log(`Fakebook listening to ${PORT}`));\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Run\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-shell\",\n        children: \"node index.js\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Test 1\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We will render friends of user 1. Only 1 level:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"http://localhost:3000/user-with-friends/1\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If we check in our console we will find:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"All good. We requested user 1 and their friends 2 and 3.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Test 2\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's try by loading 3 levels:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"http://localhost:3000/user-with-friends/1?levels=3\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Things are getting interesting here:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\nGET /users?ids=1,3\\nGET /users?ids=1,2,4\\nGET /users?ids=2,3\\nGET /users?ids=1,2,4\\nGET /users?ids=2,3\\nGET /users?ids=1,3\\nGET /users?ids=3,5\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We are loading data for users 1,2,3,4,5 but we are doing 9 requests. We are requesting the same users again and again. We could easily improve the situation adding some sort of cache per request.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Cache per request\\nWe are going to add a cache to the system. It will be empty at the start of each request, so we do not need to worry about expirations. The benefits will be:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Do not request the same resource twice to the remote source during the same request.\\nAs side effect, if we try to get the same resource twice during the same request, we will get the same data. So mutations of the resources in between a request will not provide incoherent results.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"cache.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Simple cache implementation:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"function make(loadManyFn) {\\n  const cache = {};\\n\\n  async function loadMany(ids) {\\n    const notCachedIds = ids.filter((id) => !cache[id]);\\n\\n    if (notCachedIds.length > 0) {\\n      const results = await loadManyFn(notCachedIds);\\n      notCachedIds.forEach((id, idx) => (cache[id] = results[idx]));\\n    }\\n\\n    return ids.map((id) => cache[id]);\\n  }\\n\\n  return {\\n    load: async (id) => {\\n      const results = await loadMany([id]);\\n      return results[0];\\n    },\\n    loadMany,\\n  };\\n}\\n\\nmodule.exports = { make };\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Cache needs a function to retrieve multiple data by id (or in general by a key). It will check the data that is cached and request only the ids that are not found.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Implements the same contract as datasource.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"server.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's add this line to the server:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"const cache = require('./cache')\\nAnd replace this line:\\n\\nconst user = await resolver.getUserWithFriends(datasource, id, levels)\\nwith:\\n\\nconst user = await resolver.getUserWithFriends(cache.make(datasource.loadMany), id, levels)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Run\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's run again the server and test the previous request:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"http://localhost:3000/user-with-friends/1?levels=3\\n\"\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\nGET /users?ids=4\\nGET /users?ids=4\\nGET /users?ids=5\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We could reduce the number of requests from 9 to 5, which is pretty good. But, what a momentwhat happened here? Why are we requesting id=4 twice?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If we unnest the request flow based on how nodejs works (and how we implemented our resolver) this is what happened:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"1 - Load user 1 => GET /users?ids=1\\n2 - Load friends of 1: [2,3]=> GET /users?ids=2,3\\n3.1. Load friends of 2: [1,3] => all cached\\n4.1. Load friends of 1 : [2,3] => all cached\\n4.2. Load friends of 3 : [1,2,4] => GET /users?ids=4\\n3.2. Load friends of 3: [1,2,4] => GET /users?ids=4\\n4.3. Load friends of 1: [2,3] => all cached\\n4.4. Load friends of 2: [1,3] => all cached\\n4.5. Load friends of 4: [3,5] => GET /users?ids=5\\nOn 3.1 we had all friends of user 2 cached. So the code was straight to 4.2, than ran in parallel with 3.2. Both were waiting for the same user (4) and therefore made the same requests twice.\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So with our simple cache, we did not reduce the requests to the minimun we wanted.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For example, if we did:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"const users = await Promise.all(load(1), load(1));\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"There would be 2 requests before the cache has data for id=1.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's fix this and produce the ideal:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\nGET /users?ids=4\\nGET /users?ids=5\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Dataloader\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Using nodejs \", _jsx(_components.code, {\n        children: \"process.nextTick(...)\"\n      }), \" we can postpone the execution of a given function to the end of the current event loop cycle. It is useful to run a given function after all variables are initialized for example.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"From nodejs documentation:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"By using process.nextTick() we guarantee that apiCall() always runs its callback after the rest of the user's code and before the event loop is allowed to proceed.\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Using it we can accumulate all the keys that are being requested during the same cycle (3.2 and 4.2 in the example above) and request them at the end. In the next cycle we would accumulate again the ones that were depending in the previous ones and so on.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This simple version of dataloader incorporates also code to accomplish the cache:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"function make(loadManyFn) {\\n  const cache = {};\\n  let pending = [];\\n  let scheduled = false;\\n  function scheduleSearch() {\\n    if (pending.length > 0 && !scheduled) {\\n      scheduled = true;\\n      Promise.resolve().then(() =>\\n        process.nextTick(async () => {\\n          await runSearch();\\n          scheduled = false;\\n        })\\n      );\\n    }\\n  }\\n\\n  async function runSearch() {\\n    const pendingCopy = pending.splice(0, pending.length);\\n    pending = [];\\n\\n    if (pendingCopy.length > 0) {\\n      const results = await loadManyFn(pendingCopy.map((p) => p.id));\\n      pendingCopy.forEach(({ resolve }, idx) => resolve(results[idx]));\\n    }\\n  }\\n\\n  async function loadMany(ids) {\\n    const notCachedIds = ids.filter((id) => !cache[id]);\\n\\n    if (notCachedIds.length > 0) {\\n      notCachedIds.map((id) => {\\n        cache[id] = new Promise((resolve) => {\\n          pending.push({ id, resolve });\\n        });\\n      });\\n\\n      scheduleSearch();\\n    }\\n\\n    return Promise.all(ids.map((id) => cache[id]));\\n  }\\n\\n  return {\\n    load: async (id) => {\\n      const results = await loadMany([id]);\\n      return results[0];\\n    },\\n    loadMany,\\n  };\\n}\\n\\nmodule.exports = { make };\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Ignoring the part of the cache, the important bits are:\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Accumulating requests\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"notCachedIds.map((id) => {\\n  cache[id] = new Promise((resolve) => {\\n    pending.push({ id, resolve });\\n  });\\n});\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We will add to the list of pending ids the ones that are not cached. We will keep the id and the resolve method, so we can resolve them afterwards with the right value. We cache the promise itself in the hashmap. This would allow us to cache also rejected promises for example. So we do not request over and over the same rejection. It is not used in this implementation, though.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Scheduling the request\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"function scheduleSearch() {\\n  if (pending.length > 0 && !scheduled) {\\n    scheduled = true;\\n    Promise.resolve().then(() =>\\n      process.nextTick(async () => {\\n        await runSearch();\\n        scheduled = false;\\n      })\\n    );\\n  }\\n}\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That is where the magic happens. This function is short but is the most important one: We schedule/delay the request to the end of all the promises declarations.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Executing the search\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"async function runSearch() {\\n  const pendingCopy = pending.splice(0, pending.length);\\n  pending = [];\\n\\n  if (pendingCopy.length > 0) {\\n    const results = await loadManyFn(pendingCopy.map((p) => p.id));\\n    pendingCopy.forEach(({ resolve }, idx) => resolve(results[idx]));\\n  }\\n}\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Clone the ids (so they can be accumulated again after the search completes) and call the loadManyFn so we can resolve the promises we had pending. Remember the requirements of loadMany to return the data in the right order and all the elements ? This is where it is needed. We can reference the results by index and resolve the right pending promises.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's run it!\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Execution\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Again the same request:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"http://localhost:3000/user-with-friends/1?levels=3\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That produces the following output:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\nGET /users?ids=4\\nGET /users?ids=5\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Exactly what we wanted.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Conclusion\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"Dataloader is a great package that should be in all developers toolbox. Specially the ones implementing Graphql or similar Apis.\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"The resolvers in this example could be optimized but sometimes our requests are on different files at different levels that depend on some conditions. With Dataloader we can keep our file structure and code readability without damaging our performance, both on response time to our client and on number of requests spawn within our mesh.\"\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Are you using Dataloader? Do you know any tool that accomplishes something similar? Do you now any other packages that in your opinion should be in all nodejs devs toolbox?\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}},"markdown":"# Understanding the Dataloader\n\nDataloader is one of the packages I find more useful and smart from the ones I have in my toolbox.\n\nI am going to set up a obvious naive example and follow the process to build a simple dataloader to understand its beauty and how useful it is.\n\n## About the project\n\nWe are going to create a view and api over a social network. Our users relations are:\n\n```text\nUser 1 friend of [ 2, 3 ]\nUser 2 friend of [ 1, 3 ]\nUser 3 friend of [ 1, 2, 4 ]\nUser 4 friend of [ 3, 5 ]\nUser 5 friend of [ 4 ]\n```\n\nThe view can show the relation between users and their friends. We can show N levels of their friendship. We are not goint to look much at it in this post.\n\nUsers data can be found here.\n\nThe only dependency will be express.\n\n## Initial Setup\n\n### datasource.js\n\nThe datasource allows us to retrieve one or multiple users by id. Contract is not random, it is already based on the real dataloader so there will be minimal changes over the course of the post. Data is defined in a file within the project. Code is pretty simple:\n\n```javascript\nconst users = require(\"./users.json\");\n\nconst getUsersFromFile = (ids) =>\n  ids.map((id) => users.find((u) => u.id === id));\n\nconst sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));\n\nasync function loadMany(ids) {\n  console.log(`GET /users?ids=${ids}`);\n\n  await sleep(100);\n  return getUsersFromFile(ids);\n}\n\nasync function load(id) {\n  const results = await loadMany([id]);\n  return results[0];\n}\n\nmodule.exports = {\n  load,\n  loadMany,\n};\n```\n\nThe only interesting method is loadMany. We will print the requests to the simulated service so we can check the console. There will be a delay to resolve the promise, so we can simulate better and understand why dataloader is so good.\n\nA very important requirement is that data needs to be returned to the caller in the right order and all elements need to be returned (same length of ids and results arrays). This will be clear when we put in place the dataloader.\n\n### resolver.js\n\nResolver will use the datasource received by parameter to load friendship data about users. It can receive the levels of friends we want to get, so it will use a recursive approach to load friends of friends until all levels are fetched.\n\n```javascript\nasync function getFriends(datasource, user, levels) {\n  if (levels == 0) {\n    return { id: user.id, name: user.name };\n  }\n\n  const friends = await datasource.loadMany(user.friends);\n\n  return {\n    ...user,\n    friends: await Promise.all(\n      friends.map((f) => getFriends(datasource, f, levels - 1))\n    ),\n  };\n}\n\nasync function getUserWithFriends(datasource, id, levels = 1) {\n  const user = await datasource.load(id);\n  return getFriends(datasource, user, levels);\n}\n\nmodule.exports = { getUserWithFriends };\n```\n\nIt uses a brute force approach on purpose. The code is simple but far away from being optimal. In one method it looks obvious, but sometimes, when we are building graphql or similar apis, or complex workflows we might be doing exactly this kind of brute force requests.\n\n### view.js\n\nNothing advanced. Just render users friends in a nested way.\n\n```javascript\nfunction render(user) {\n  return `<div style=\"padding-left: 12px;background-color:#def\"> ${user.name} ${\n    user.friends ? user.friends.map((u) => render(u)).join(\"\") : \"\"\n  } </div>`;\n}\n\nmodule.exports = {\n  render,\n};\n```\n\n### server.js\n\n```javascript\nconst express = require(\"express\");\nconst PORT = 3000;\nconst app = express();\n\nconst datasource = require(\"./datasource\");\nconst resolver = require(\"./resolver\");\nconst view = require(\"./view\");\n\napp.get(`/user-with-friends/:id`, async (req, res) => {\n  const id = req.params.id;\n  const levels = req.query.levels || 1;\n\n  const user = await resolver.getUserWithFriends(datasource, id, levels);\n\n  res.send(view.render(user));\n});\n\napp.listen(PORT, () => console.log(`Fakebook listening to ${PORT}`));\n```\n\n## Run\n\n```shell\nnode index.js\n```\n\n## Test 1\n\nWe will render friends of user 1. Only 1 level:\n\n```text\nhttp://localhost:3000/user-with-friends/1\n```\n\nIf we check in our console we will find:\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\n```\n\nAll good. We requested user 1 and their friends 2 and 3.\n\n## Test 2\n\nLet's try by loading 3 levels:\n\n```text\nhttp://localhost:3000/user-with-friends/1?levels=3\n```\n\nThings are getting interesting here:\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\nGET /users?ids=1,3\nGET /users?ids=1,2,4\nGET /users?ids=2,3\nGET /users?ids=1,2,4\nGET /users?ids=2,3\nGET /users?ids=1,3\nGET /users?ids=3,5\n```\n\nWe are loading data for users 1,2,3,4,5 but we are doing 9 requests. We are requesting the same users again and again. We could easily improve the situation adding some sort of cache per request.\n\nCache per request\nWe are going to add a cache to the system. It will be empty at the start of each request, so we do not need to worry about expirations. The benefits will be:\n\nDo not request the same resource twice to the remote source during the same request.\nAs side effect, if we try to get the same resource twice during the same request, we will get the same data. So mutations of the resources in between a request will not provide incoherent results.\n\n### cache.js\n\nSimple cache implementation:\n\n```javascript\nfunction make(loadManyFn) {\n  const cache = {};\n\n  async function loadMany(ids) {\n    const notCachedIds = ids.filter((id) => !cache[id]);\n\n    if (notCachedIds.length > 0) {\n      const results = await loadManyFn(notCachedIds);\n      notCachedIds.forEach((id, idx) => (cache[id] = results[idx]));\n    }\n\n    return ids.map((id) => cache[id]);\n  }\n\n  return {\n    load: async (id) => {\n      const results = await loadMany([id]);\n      return results[0];\n    },\n    loadMany,\n  };\n}\n\nmodule.exports = { make };\n```\n\nCache needs a function to retrieve multiple data by id (or in general by a key). It will check the data that is cached and request only the ids that are not found.\n\nImplements the same contract as datasource.\n\n### server.js\n\nLet's add this line to the server:\n\n```javascript\nconst cache = require('./cache')\nAnd replace this line:\n\nconst user = await resolver.getUserWithFriends(datasource, id, levels)\nwith:\n\nconst user = await resolver.getUserWithFriends(cache.make(datasource.loadMany), id, levels)\n```\n\n## Run\n\nLet's run again the server and test the previous request:\n\n```text\nhttp://localhost:3000/user-with-friends/1?levels=3\n```\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\nGET /users?ids=4\nGET /users?ids=4\nGET /users?ids=5\n```\n\nWe could reduce the number of requests from 9 to 5, which is pretty good. But, what a momentwhat happened here? Why are we requesting id=4 twice?\n\nIf we unnest the request flow based on how nodejs works (and how we implemented our resolver) this is what happened:\n\n```text\n1 - Load user 1 => GET /users?ids=1\n2 - Load friends of 1: [2,3]=> GET /users?ids=2,3\n3.1. Load friends of 2: [1,3] => all cached\n4.1. Load friends of 1 : [2,3] => all cached\n4.2. Load friends of 3 : [1,2,4] => GET /users?ids=4\n3.2. Load friends of 3: [1,2,4] => GET /users?ids=4\n4.3. Load friends of 1: [2,3] => all cached\n4.4. Load friends of 2: [1,3] => all cached\n4.5. Load friends of 4: [3,5] => GET /users?ids=5\nOn 3.1 we had all friends of user 2 cached. So the code was straight to 4.2, than ran in parallel with 3.2. Both were waiting for the same user (4) and therefore made the same requests twice.\n```\n\nSo with our simple cache, we did not reduce the requests to the minimun we wanted.\n\nFor example, if we did:\n\n```javascript\nconst users = await Promise.all(load(1), load(1));\n```\n\nThere would be 2 requests before the cache has data for id=1.\n\nLet's fix this and produce the ideal:\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\nGET /users?ids=4\nGET /users?ids=5\n```\n\n## Dataloader\n\nUsing nodejs `process.nextTick(...)` we can postpone the execution of a given function to the end of the current event loop cycle. It is useful to run a given function after all variables are initialized for example.\n\nFrom nodejs documentation:\n\n```text\nBy using process.nextTick() we guarantee that apiCall() always runs its callback after the rest of the user's code and before the event loop is allowed to proceed.\n```\n\nUsing it we can accumulate all the keys that are being requested during the same cycle (3.2 and 4.2 in the example above) and request them at the end. In the next cycle we would accumulate again the ones that were depending in the previous ones and so on.\n\nThis simple version of dataloader incorporates also code to accomplish the cache:\n\n```javascript\nfunction make(loadManyFn) {\n  const cache = {};\n  let pending = [];\n  let scheduled = false;\n  function scheduleSearch() {\n    if (pending.length > 0 && !scheduled) {\n      scheduled = true;\n      Promise.resolve().then(() =>\n        process.nextTick(async () => {\n          await runSearch();\n          scheduled = false;\n        })\n      );\n    }\n  }\n\n  async function runSearch() {\n    const pendingCopy = pending.splice(0, pending.length);\n    pending = [];\n\n    if (pendingCopy.length > 0) {\n      const results = await loadManyFn(pendingCopy.map((p) => p.id));\n      pendingCopy.forEach(({ resolve }, idx) => resolve(results[idx]));\n    }\n  }\n\n  async function loadMany(ids) {\n    const notCachedIds = ids.filter((id) => !cache[id]);\n\n    if (notCachedIds.length > 0) {\n      notCachedIds.map((id) => {\n        cache[id] = new Promise((resolve) => {\n          pending.push({ id, resolve });\n        });\n      });\n\n      scheduleSearch();\n    }\n\n    return Promise.all(ids.map((id) => cache[id]));\n  }\n\n  return {\n    load: async (id) => {\n      const results = await loadMany([id]);\n      return results[0];\n    },\n    loadMany,\n  };\n}\n\nmodule.exports = { make };\n```\n\nIgnoring the part of the cache, the important bits are:\n\n### Accumulating requests\n\n```javascript\nnotCachedIds.map((id) => {\n  cache[id] = new Promise((resolve) => {\n    pending.push({ id, resolve });\n  });\n});\n```\n\nWe will add to the list of pending ids the ones that are not cached. We will keep the id and the resolve method, so we can resolve them afterwards with the right value. We cache the promise itself in the hashmap. This would allow us to cache also rejected promises for example. So we do not request over and over the same rejection. It is not used in this implementation, though.\n\n### Scheduling the request\n\n```javascript\nfunction scheduleSearch() {\n  if (pending.length > 0 && !scheduled) {\n    scheduled = true;\n    Promise.resolve().then(() =>\n      process.nextTick(async () => {\n        await runSearch();\n        scheduled = false;\n      })\n    );\n  }\n}\n```\n\nThat is where the magic happens. This function is short but is the most important one: We schedule/delay the request to the end of all the promises declarations.\n\n### Executing the search\n\n```javascript\nasync function runSearch() {\n  const pendingCopy = pending.splice(0, pending.length);\n  pending = [];\n\n  if (pendingCopy.length > 0) {\n    const results = await loadManyFn(pendingCopy.map((p) => p.id));\n    pendingCopy.forEach(({ resolve }, idx) => resolve(results[idx]));\n  }\n}\n```\n\nClone the ids (so they can be accumulated again after the search completes) and call the loadManyFn so we can resolve the promises we had pending. Remember the requirements of loadMany to return the data in the right order and all the elements ? This is where it is needed. We can reference the results by index and resolve the right pending promises.\n\nLet's run it!\n\n## Execution\n\nAgain the same request:\n\n```text\nhttp://localhost:3000/user-with-friends/1?levels=3\n```\n\nThat produces the following output:\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\nGET /users?ids=4\nGET /users?ids=5\n```\n\nExactly what we wanted.\n\n## Conclusion\n\n- Dataloader is a great package that should be in all developers toolbox. Specially the ones implementing Graphql or similar Apis.\n\n- The resolvers in this example could be optimized but sometimes our requests are on different files at different levels that depend on some conditions. With Dataloader we can keep our file structure and code readability without damaging our performance, both on response time to our client and on number of requests spawn within our mesh.\n\nAre you using Dataloader? Do you know any tool that accomplishes something similar? Do you now any other packages that in your opinion should be in all nodejs devs toolbox?\n"}},"__N_SSG":true}