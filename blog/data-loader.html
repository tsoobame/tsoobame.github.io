<!DOCTYPE html><html lang="en" style="height:100%"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Tsoobame - Understanding data loader</title><meta name="next-head-count" content="3"/><title>Tsoobame</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Z67DVHFVCM"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'G-Z67DVHFVCM', {
              page_path: window.location.pathname,
            });
          </script><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8646ebd196ee32a0.js" defer=""></script><script src="/_next/static/chunks/framework-9b5d6ec4444c80fa.js" defer=""></script><script src="/_next/static/chunks/main-acfafc49f148be44.js" defer=""></script><script src="/_next/static/chunks/pages/_app-03b41647443f3278.js" defer=""></script><script src="/_next/static/chunks/181-fa4e5b0dcaf48e99.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-4afd1af938b86671.js" defer=""></script><script src="/_next/static/AWYFh2Cu81pZ9PtCaFAIO/_buildManifest.js" defer=""></script><script src="/_next/static/AWYFh2Cu81pZ9PtCaFAIO/_ssgManifest.js" defer=""></script><style id="jss-server-side">.jss1 {
  background: linear-gradient(90deg, #00766c, #0077c2);
}
.jss3 {
  overflow-x: auto;
  justify-content: space-between;
}
.jss4 {
  padding: 8px;
  flex-shrink: 0;
}
.jss5 {
  top: 0;
  left: 0;
  right: 0;
  width: 100%;
  z-index: 1;
  position: fixed;
}
.jss6 {
  color: #FFFFFF;
  width: 100%;
  bottom: 0;
  padding: 16px 0px;
  z-index: 99;
  position: fixed;
  background: linear-gradient(90deg, #00766c, #0077c2);
}</style></head><body style="padding:0;margin:0;min-height:100%"><div id="__next"><style data-emotion="css 1a51u83">.css-1a51u83{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:static;background-color:#26a69a;color:#FFFFFF;}</style><style data-emotion="css 1rhdqfh">.css-1rhdqfh{background-color:#FFFFFF;color:#263238;-webkit-transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;box-shadow:0px 2px 4px -1px rgba(0,0,0,0.2),0px 4px 5px 0px rgba(0,0,0,0.14),0px 1px 10px 0px rgba(0,0,0,0.12);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:static;background-color:#26a69a;color:#FFFFFF;}</style><header class="MuiPaper-root MuiPaper-elevation MuiPaper-elevation4 MuiAppBar-root MuiAppBar-colorPrimary MuiAppBar-positionStatic jss5 css-1rhdqfh" style="padding:0"><style data-emotion="css i6s8oy">.css-i6s8oy{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;padding-right:16px;min-height:56px;}@media (min-width:600px){.css-i6s8oy{padding-left:24px;padding-right:24px;}}@media (min-width:0px){@media (orientation: landscape){.css-i6s8oy{min-height:48px;}}}@media (min-width:600px){.css-i6s8oy{min-height:64px;}}</style><div class="MuiToolbar-root MuiToolbar-gutters MuiToolbar-regular jss1 css-i6s8oy"><style data-emotion="css 18zcnv2">.css-18zcnv2{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1.5rem;line-height:1.334;letter-spacing:0em;text-align:center;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;color:inherit;}</style><h2 class="MuiTypography-root MuiTypography-h5 MuiTypography-alignCenter MuiTypography-noWrap jss2 css-18zcnv2"><style data-emotion="css 1cik1k3">.css-1cik1k3{-webkit-text-decoration:underline;text-decoration:underline;color:inherit;}.css-1cik1k3:hover{text-decoration-color:inherit;}</style><style data-emotion="css 1c0wj8h">.css-1c0wj8h{margin:0;color:inherit;-webkit-text-decoration:underline;text-decoration:underline;color:inherit;}.css-1c0wj8h:hover{text-decoration-color:inherit;}</style><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-1c0wj8h" style="text-decoration:none" href="/">tsoobame</a></h2><style data-emotion="css i9gxme">.css-i9gxme{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><div class="MuiBox-root css-i9gxme"><style data-emotion="css 4fvm0a">.css-4fvm0a{font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:500;font-size:0.875rem;line-height:1.75;letter-spacing:0.02857em;text-transform:uppercase;min-width:64px;padding:6px 8px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#26a69a;color:#FFFFFF;}.css-4fvm0a:hover{-webkit-text-decoration:none;text-decoration:none;background-color:rgba(38, 166, 154, 0.04);}@media (hover: none){.css-4fvm0a:hover{background-color:transparent;}}.css-4fvm0a.Mui-disabled{color:rgba(0, 0, 0, 0.26);}</style><style data-emotion="css ye6gas">.css-ye6gas{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:500;font-size:0.875rem;line-height:1.75;letter-spacing:0.02857em;text-transform:uppercase;min-width:64px;padding:6px 8px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#26a69a;color:#FFFFFF;}.css-ye6gas::-moz-focus-inner{border-style:none;}.css-ye6gas.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-ye6gas{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-ye6gas:hover{-webkit-text-decoration:none;text-decoration:none;background-color:rgba(38, 166, 154, 0.04);}@media (hover: none){.css-ye6gas:hover{background-color:transparent;}}.css-ye6gas.Mui-disabled{color:rgba(0, 0, 0, 0.26);}</style><button class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium css-ye6gas" tabindex="0" type="button"><a style="color:white;text-decoration:none" href="/blog">Blog</a></button><button class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium css-ye6gas" tabindex="0" type="button"><a style="color:white;text-decoration:none" href="/about">About</a></button><button class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium css-ye6gas" tabindex="0" type="button"><a style="color:white;text-decoration:none" href="/projects">Projects</a></button><button class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium css-ye6gas" tabindex="0" type="button"><a style="color:white;text-decoration:none" href="/recommended-resources">Resources</a></button></div></div></header><div class="MuiBox-root css-0" style="position:relative;width:90%;padding-left:24px;padding-right:24px;margin-top:80px;margin-bottom:90px;z-index:0;min-height:100%"><div class="MuiBox-root css-0" style="width:auto;padding:12px"><style data-emotion="css 15bqboc">.css-15bqboc{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}</style><div class="MuiGrid-root MuiGrid-container css-15bqboc"><style data-emotion="css 13ps8n2">.css-13ps8n2{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}@media (min-width:600px){.css-13ps8n2{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:900px){.css-13ps8n2{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1200px){.css-13ps8n2{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1536px){.css-13ps8n2{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-sm-12 MuiGrid-grid-md-3 css-13ps8n2" style="padding:6px"><div><style data-emotion="css t1nuxs">.css-t1nuxs{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1.5rem;line-height:1.334;letter-spacing:0em;margin-bottom:0.35em;}</style><h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs">Posts </h5><ul style="list-style-type:none"><li><style data-emotion="css 9l3uo3">.css-9l3uo3{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1rem;line-height:1.5;letter-spacing:0.00938em;}</style><p class="MuiTypography-root MuiTypography-body1 css-9l3uo3"><a style="text-decoration:none;color:gray" href="/blog/data-loader">Understanding data loader</a></p></li><li><p class="MuiTypography-root MuiTypography-body1 css-9l3uo3"><a style="text-decoration:none;color:gray" href="/blog/graphql-schema-stitching">Graphql Schema Stitching</a></p></li><li><p class="MuiTypography-root MuiTypography-body1 css-9l3uo3"><a style="text-decoration:none;color:gray" href="/blog/shape-vs-optionality">Decomplecting shape and optionality</a></p></li></ul></div></div><style data-emotion="css 1xd5sck">.css-1xd5sck{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}@media (min-width:600px){.css-1xd5sck{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:900px){.css-1xd5sck{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1200px){.css-1xd5sck{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1536px){.css-1xd5sck{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-md-9 css-1xd5sck"><img src="/images/data-loader.jpeg" style="height:200px;object-fit:cover" width="100%" height="200"/><p class="MuiTypography-root MuiTypography-body1 css-9l3uo3">⏱ <!-- -->8 min read</p><div class="MuiBox-root css-0"><style data-emotion="css 6s8q25">.css-6s8q25{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:3rem;line-height:1.167;letter-spacing:0em;margin-bottom:0.35em;}</style><h3 class="MuiTypography-root MuiTypography-h3 MuiTypography-gutterBottom css-6s8q25" style="margin-top:24px">Understanding the Dataloader</h3>
<style data-emotion="css wje1bd">.css-wje1bd{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1rem;line-height:1.5;letter-spacing:0.00938em;margin-bottom:16px;}</style><p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Dataloader is one of the packages I find more useful and smart from the ones I have in my toolbox.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">I am going to set up a obvious naive example and follow the process to build a simple dataloader to understand its beauty and how useful it is.</p>
<style data-emotion="css gtvj52">.css-gtvj52{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:2.125rem;line-height:1.235;letter-spacing:0.00735em;margin-bottom:0.35em;}</style><h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">About the project</h4>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">We are going to create a view and api over a social network. Our users relations are:</p>
<pre><code class="language-text">User 1 friend of [ 2, 3 ]
User 2 friend of [ 1, 3 ]
User 3 friend of [ 1, 2, 4 ]
User 4 friend of [ 3, 5 ]
User 5 friend of [ 4 ]
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">The view can show the relation between users and their friends. We can show N levels of their friendship. We are not goint to look much at it in this post.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Users data can be found here.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">The only dependency will be express.</p>
<h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">Initial Setup</h4>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">datasource.js</h5>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">The datasource allows us to retrieve one or multiple users by id. Contract is not random, it is already based on the real dataloader so there will be minimal changes over the course of the post. Data is defined in a file within the project. Code is pretty simple:</p>
<pre><code class="language-javascript">const users = require(&quot;./users.json&quot;);

const getUsersFromFile = (ids) =&gt;
  ids.map((id) =&gt; users.find((u) =&gt; u.id === id));

const sleep = (ms) =&gt; new Promise((resolve) =&gt; setTimeout(resolve, ms));

async function loadMany(ids) {
  console.log(`GET /users?ids=${ids}`);

  await sleep(100);
  return getUsersFromFile(ids);
}

async function load(id) {
  const results = await loadMany([id]);
  return results[0];
}

module.exports = {
  load,
  loadMany,
};
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">The only interesting method is loadMany. We will print the requests to the simulated service so we can check the console. There will be a delay to resolve the promise, so we can simulate better and understand why dataloader is so good.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">A very important requirement is that data needs to be returned to the caller in the right order and all elements need to be returned (same length of ids and results arrays). This will be clear when we put in place the dataloader.</p>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">resolver.js</h5>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Resolver will use the datasource received by parameter to load friendship data about users. It can receive the levels of friends we want to get, so it will use a recursive approach to load friends of friends until all levels are fetched.</p>
<pre><code class="language-javascript">async function getFriends(datasource, user, levels) {
  if (levels == 0) {
    return { id: user.id, name: user.name };
  }

  const friends = await datasource.loadMany(user.friends);

  return {
    ...user,
    friends: await Promise.all(
      friends.map((f) =&gt; getFriends(datasource, f, levels - 1))
    ),
  };
}

async function getUserWithFriends(datasource, id, levels = 1) {
  const user = await datasource.load(id);
  return getFriends(datasource, user, levels);
}

module.exports = { getUserWithFriends };
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">It uses a brute force approach on purpose. The code is simple but far away from being optimal. In one method it looks obvious, but sometimes, when we are building graphql or similar apis, or complex workflows we might be doing exactly this kind of brute force requests.</p>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">view.js</h5>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Nothing advanced. Just render users friends in a nested way.</p>
<pre><code class="language-javascript">function render(user) {
  return `&lt;div style=&quot;padding-left: 12px;background-color:#def&quot;&gt; ${user.name} ${
    user.friends ? user.friends.map((u) =&gt; render(u)).join(&quot;&quot;) : &quot;&quot;
  } &lt;/div&gt;`;
}

module.exports = {
  render,
};
</code></pre>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">server.js</h5>
<pre><code class="language-javascript">const express = require(&quot;express&quot;);
const PORT = 3000;
const app = express();

const datasource = require(&quot;./datasource&quot;);
const resolver = require(&quot;./resolver&quot;);
const view = require(&quot;./view&quot;);

app.get(`/user-with-friends/:id`, async (req, res) =&gt; {
  const id = req.params.id;
  const levels = req.query.levels || 1;

  const user = await resolver.getUserWithFriends(datasource, id, levels);

  res.send(view.render(user));
});

app.listen(PORT, () =&gt; console.log(`Fakebook listening to ${PORT}`));
</code></pre>
<h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">Run</h4>
<pre><code class="language-shell">node index.js
</code></pre>
<h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">Test 1</h4>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">We will render friends of user 1. Only 1 level:</p>
<pre><code class="language-text">http://localhost:3000/user-with-friends/1
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">If we check in our console we will find:</p>
<pre><code class="language-text">GET /users?ids=1
GET /users?ids=2,3
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">All good. We requested user 1 and their friends 2 and 3.</p>
<h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">Test 2</h4>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Let&#x27;s try by loading 3 levels:</p>
<pre><code class="language-text">http://localhost:3000/user-with-friends/1?levels=3
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Things are getting interesting here:</p>
<pre><code class="language-text">GET /users?ids=1
GET /users?ids=2,3
GET /users?ids=1,3
GET /users?ids=1,2,4
GET /users?ids=2,3
GET /users?ids=1,2,4
GET /users?ids=2,3
GET /users?ids=1,3
GET /users?ids=3,5
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">We are loading data for users 1,2,3,4,5 but we are doing 9 requests. We are requesting the same users again and again. We could easily improve the situation adding some sort of cache per request.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Cache per request
We are going to add a cache to the system. It will be empty at the start of each request, so we do not need to worry about expirations. The benefits will be:</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Do not request the same resource twice to the remote source during the same request.
As side effect, if we try to get the same resource twice during the same request, we will get the same data. So mutations of the resources in between a request will not provide incoherent results.</p>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">cache.js</h5>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Simple cache implementation:</p>
<pre><code class="language-javascript">function make(loadManyFn) {
  const cache = {};

  async function loadMany(ids) {
    const notCachedIds = ids.filter((id) =&gt; !cache[id]);

    if (notCachedIds.length &gt; 0) {
      const results = await loadManyFn(notCachedIds);
      notCachedIds.forEach((id, idx) =&gt; (cache[id] = results[idx]));
    }

    return ids.map((id) =&gt; cache[id]);
  }

  return {
    load: async (id) =&gt; {
      const results = await loadMany([id]);
      return results[0];
    },
    loadMany,
  };
}

module.exports = { make };
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Cache needs a function to retrieve multiple data by id (or in general by a key). It will check the data that is cached and request only the ids that are not found.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Implements the same contract as datasource.</p>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">server.js</h5>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Let&#x27;s add this line to the server:</p>
<pre><code class="language-javascript">const cache = require(&#x27;./cache&#x27;)
And replace this line:

const user = await resolver.getUserWithFriends(datasource, id, levels)
with:

const user = await resolver.getUserWithFriends(cache.make(datasource.loadMany), id, levels)
</code></pre>
<h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">Run</h4>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Let&#x27;s run again the server and test the previous request:</p>
<pre><code class="language-text">http://localhost:3000/user-with-friends/1?levels=3
</code></pre>
<pre><code class="language-text">GET /users?ids=1
GET /users?ids=2,3
GET /users?ids=4
GET /users?ids=4
GET /users?ids=5
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">We could reduce the number of requests from 9 to 5, which is pretty good. But, what a momentwhat happened here? Why are we requesting id=4 twice?</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">If we unnest the request flow based on how nodejs works (and how we implemented our resolver) this is what happened:</p>
<pre><code class="language-text">1 - Load user 1 =&gt; GET /users?ids=1
2 - Load friends of 1: [2,3]=&gt; GET /users?ids=2,3
3.1. Load friends of 2: [1,3] =&gt; all cached
4.1. Load friends of 1 : [2,3] =&gt; all cached
4.2. Load friends of 3 : [1,2,4] =&gt; GET /users?ids=4
3.2. Load friends of 3: [1,2,4] =&gt; GET /users?ids=4
4.3. Load friends of 1: [2,3] =&gt; all cached
4.4. Load friends of 2: [1,3] =&gt; all cached
4.5. Load friends of 4: [3,5] =&gt; GET /users?ids=5
On 3.1 we had all friends of user 2 cached. So the code was straight to 4.2, than ran in parallel with 3.2. Both were waiting for the same user (4) and therefore made the same requests twice.
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">So with our simple cache, we did not reduce the requests to the minimun we wanted.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">For example, if we did:</p>
<pre><code class="language-javascript">const users = await Promise.all(load(1), load(1));
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">There would be 2 requests before the cache has data for id=1.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Let&#x27;s fix this and produce the ideal:</p>
<pre><code class="language-text">GET /users?ids=1
GET /users?ids=2,3
GET /users?ids=4
GET /users?ids=5
</code></pre>
<h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">Dataloader</h4>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Using nodejs <code>process.nextTick(...)</code> we can postpone the execution of a given function to the end of the current event loop cycle. It is useful to run a given function after all variables are initialized for example.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">From nodejs documentation:</p>
<pre><code class="language-text">By using process.nextTick() we guarantee that apiCall() always runs its callback after the rest of the user&#x27;s code and before the event loop is allowed to proceed.
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Using it we can accumulate all the keys that are being requested during the same cycle (3.2 and 4.2 in the example above) and request them at the end. In the next cycle we would accumulate again the ones that were depending in the previous ones and so on.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">This simple version of dataloader incorporates also code to accomplish the cache:</p>
<pre><code class="language-javascript">function make(loadManyFn) {
  const cache = {};
  let pending = [];
  let scheduled = false;
  function scheduleSearch() {
    if (pending.length &gt; 0 &amp;&amp; !scheduled) {
      scheduled = true;
      Promise.resolve().then(() =&gt;
        process.nextTick(async () =&gt; {
          await runSearch();
          scheduled = false;
        })
      );
    }
  }

  async function runSearch() {
    const pendingCopy = pending.splice(0, pending.length);
    pending = [];

    if (pendingCopy.length &gt; 0) {
      const results = await loadManyFn(pendingCopy.map((p) =&gt; p.id));
      pendingCopy.forEach(({ resolve }, idx) =&gt; resolve(results[idx]));
    }
  }

  async function loadMany(ids) {
    const notCachedIds = ids.filter((id) =&gt; !cache[id]);

    if (notCachedIds.length &gt; 0) {
      notCachedIds.map((id) =&gt; {
        cache[id] = new Promise((resolve) =&gt; {
          pending.push({ id, resolve });
        });
      });

      scheduleSearch();
    }

    return Promise.all(ids.map((id) =&gt; cache[id]));
  }

  return {
    load: async (id) =&gt; {
      const results = await loadMany([id]);
      return results[0];
    },
    loadMany,
  };
}

module.exports = { make };
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Ignoring the part of the cache, the important bits are:</p>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">Accumulating requests</h5>
<pre><code class="language-javascript">notCachedIds.map((id) =&gt; {
  cache[id] = new Promise((resolve) =&gt; {
    pending.push({ id, resolve });
  });
});
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">We will add to the list of pending ids the ones that are not cached. We will keep the id and the resolve method, so we can resolve them afterwards with the right value. We cache the promise itself in the hashmap. This would allow us to cache also rejected promises for example. So we do not request over and over the same rejection. It is not used in this implementation, though.</p>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">Scheduling the request</h5>
<pre><code class="language-javascript">function scheduleSearch() {
  if (pending.length &gt; 0 &amp;&amp; !scheduled) {
    scheduled = true;
    Promise.resolve().then(() =&gt;
      process.nextTick(async () =&gt; {
        await runSearch();
        scheduled = false;
      })
    );
  }
}
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">That is where the magic happens. This function is short but is the most important one: We schedule/delay the request to the end of all the promises declarations.</p>
<h5 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs" style="margin-top:24px">Executing the search</h5>
<pre><code class="language-javascript">async function runSearch() {
  const pendingCopy = pending.splice(0, pending.length);
  pending = [];

  if (pendingCopy.length &gt; 0) {
    const results = await loadManyFn(pendingCopy.map((p) =&gt; p.id));
    pendingCopy.forEach(({ resolve }, idx) =&gt; resolve(results[idx]));
  }
}
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Clone the ids (so they can be accumulated again after the search completes) and call the loadManyFn so we can resolve the promises we had pending. Remember the requirements of loadMany to return the data in the right order and all the elements ? This is where it is needed. We can reference the results by index and resolve the right pending promises.</p>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Let&#x27;s run it!</p>
<h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">Execution</h4>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Again the same request:</p>
<pre><code class="language-text">http://localhost:3000/user-with-friends/1?levels=3
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">That produces the following output:</p>
<pre><code class="language-text">GET /users?ids=1
GET /users?ids=2,3
GET /users?ids=4
GET /users?ids=5
</code></pre>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Exactly what we wanted.</p>
<h4 class="MuiTypography-root MuiTypography-h4 MuiTypography-gutterBottom css-gtvj52" style="margin-top:24px">Conclusion</h4>
<ul>
<li><p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify;margin-bottom:3px">
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Dataloader is a great package that should be in all developers toolbox. Specially the ones implementing Graphql or similar Apis.</p>
</p></li>
<li><p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify;margin-bottom:3px">
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">The resolvers in this example could be optimized but sometimes our requests are on different files at different levels that depend on some conditions. With Dataloader we can keep our file structure and code readability without damaging our performance, both on response time to our client and on number of requests spawn within our mesh.</p>
</p></li>
</ul>
<p class="MuiTypography-root MuiTypography-body1 MuiTypography-paragraph css-wje1bd" style="text-align:justify">Are you using Dataloader? Do you know any tool that accomplishes something similar? Do you now any other packages that in your opinion should be in all nodejs devs toolbox?</p></div></div></div></div></div><footer class="jss6"><style data-emotion="css 1qsxih2">.css-1qsxih2{width:100%;margin-left:auto;box-sizing:border-box;margin-right:auto;display:block;padding-left:16px;padding-right:16px;}@media (min-width:600px){.css-1qsxih2{padding-left:24px;padding-right:24px;}}@media (min-width:1200px){.css-1qsxih2{max-width:1200px;}}</style><div class="MuiContainer-root MuiContainer-maxWidthLg css-1qsxih2"><style data-emotion="css 1is0dyx">.css-1is0dyx{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:0.875rem;line-height:1.43;letter-spacing:0.01071em;text-align:center;color:inherit;}</style><p class="MuiTypography-root MuiTypography-body2 MuiTypography-alignCenter css-1is0dyx">Copyright © <!-- -->tonitienda <!-- -->2022<!-- -->.</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Understanding data loader","date":"2020-07-19","description":"Create a basic dataloader to understand this great library","thumbnail":{"url":"/images/data-loader.jpeg","attribution":{"name":"Lars Kienle","url":"https://unsplash.com/@larskienle?utm_source=unsplash\u0026utm_medium=referral\u0026utm_content=creditCopyText"}},"tags":["javascript"],"filePath":"data-loader.mdx","slug":"data-loader","mdxSource":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h1: \"h1\",\n    p: \"p\",\n    h2: \"h2\",\n    pre: \"pre\",\n    code: \"code\",\n    h3: \"h3\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.h1, {\n      children: \"Understanding the Dataloader\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Dataloader is one of the packages I find more useful and smart from the ones I have in my toolbox.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"I am going to set up a obvious naive example and follow the process to build a simple dataloader to understand its beauty and how useful it is.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"About the project\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We are going to create a view and api over a social network. Our users relations are:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"User 1 friend of [ 2, 3 ]\\nUser 2 friend of [ 1, 3 ]\\nUser 3 friend of [ 1, 2, 4 ]\\nUser 4 friend of [ 3, 5 ]\\nUser 5 friend of [ 4 ]\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The view can show the relation between users and their friends. We can show N levels of their friendship. We are not goint to look much at it in this post.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Users data can be found here.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The only dependency will be express.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Initial Setup\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"datasource.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The datasource allows us to retrieve one or multiple users by id. Contract is not random, it is already based on the real dataloader so there will be minimal changes over the course of the post. Data is defined in a file within the project. Code is pretty simple:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"const users = require(\\\"./users.json\\\");\\n\\nconst getUsersFromFile = (ids) =\u003e\\n  ids.map((id) =\u003e users.find((u) =\u003e u.id === id));\\n\\nconst sleep = (ms) =\u003e new Promise((resolve) =\u003e setTimeout(resolve, ms));\\n\\nasync function loadMany(ids) {\\n  console.log(`GET /users?ids=${ids}`);\\n\\n  await sleep(100);\\n  return getUsersFromFile(ids);\\n}\\n\\nasync function load(id) {\\n  const results = await loadMany([id]);\\n  return results[0];\\n}\\n\\nmodule.exports = {\\n  load,\\n  loadMany,\\n};\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The only interesting method is loadMany. We will print the requests to the simulated service so we can check the console. There will be a delay to resolve the promise, so we can simulate better and understand why dataloader is so good.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A very important requirement is that data needs to be returned to the caller in the right order and all elements need to be returned (same length of ids and results arrays). This will be clear when we put in place the dataloader.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"resolver.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Resolver will use the datasource received by parameter to load friendship data about users. It can receive the levels of friends we want to get, so it will use a recursive approach to load friends of friends until all levels are fetched.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"async function getFriends(datasource, user, levels) {\\n  if (levels == 0) {\\n    return { id: user.id, name: user.name };\\n  }\\n\\n  const friends = await datasource.loadMany(user.friends);\\n\\n  return {\\n    ...user,\\n    friends: await Promise.all(\\n      friends.map((f) =\u003e getFriends(datasource, f, levels - 1))\\n    ),\\n  };\\n}\\n\\nasync function getUserWithFriends(datasource, id, levels = 1) {\\n  const user = await datasource.load(id);\\n  return getFriends(datasource, user, levels);\\n}\\n\\nmodule.exports = { getUserWithFriends };\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"It uses a brute force approach on purpose. The code is simple but far away from being optimal. In one method it looks obvious, but sometimes, when we are building graphql or similar apis, or complex workflows we might be doing exactly this kind of brute force requests.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"view.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Nothing advanced. Just render users friends in a nested way.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"function render(user) {\\n  return `\u003cdiv style=\\\"padding-left: 12px;background-color:#def\\\"\u003e ${user.name} ${\\n    user.friends ? user.friends.map((u) =\u003e render(u)).join(\\\"\\\") : \\\"\\\"\\n  } \u003c/div\u003e`;\\n}\\n\\nmodule.exports = {\\n  render,\\n};\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"server.js\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"const express = require(\\\"express\\\");\\nconst PORT = 3000;\\nconst app = express();\\n\\nconst datasource = require(\\\"./datasource\\\");\\nconst resolver = require(\\\"./resolver\\\");\\nconst view = require(\\\"./view\\\");\\n\\napp.get(`/user-with-friends/:id`, async (req, res) =\u003e {\\n  const id = req.params.id;\\n  const levels = req.query.levels || 1;\\n\\n  const user = await resolver.getUserWithFriends(datasource, id, levels);\\n\\n  res.send(view.render(user));\\n});\\n\\napp.listen(PORT, () =\u003e console.log(`Fakebook listening to ${PORT}`));\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Run\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-shell\",\n        children: \"node index.js\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Test 1\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We will render friends of user 1. Only 1 level:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"http://localhost:3000/user-with-friends/1\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If we check in our console we will find:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"All good. We requested user 1 and their friends 2 and 3.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Test 2\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's try by loading 3 levels:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"http://localhost:3000/user-with-friends/1?levels=3\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Things are getting interesting here:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\nGET /users?ids=1,3\\nGET /users?ids=1,2,4\\nGET /users?ids=2,3\\nGET /users?ids=1,2,4\\nGET /users?ids=2,3\\nGET /users?ids=1,3\\nGET /users?ids=3,5\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We are loading data for users 1,2,3,4,5 but we are doing 9 requests. We are requesting the same users again and again. We could easily improve the situation adding some sort of cache per request.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Cache per request\\nWe are going to add a cache to the system. It will be empty at the start of each request, so we do not need to worry about expirations. The benefits will be:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Do not request the same resource twice to the remote source during the same request.\\nAs side effect, if we try to get the same resource twice during the same request, we will get the same data. So mutations of the resources in between a request will not provide incoherent results.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"cache.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Simple cache implementation:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"function make(loadManyFn) {\\n  const cache = {};\\n\\n  async function loadMany(ids) {\\n    const notCachedIds = ids.filter((id) =\u003e !cache[id]);\\n\\n    if (notCachedIds.length \u003e 0) {\\n      const results = await loadManyFn(notCachedIds);\\n      notCachedIds.forEach((id, idx) =\u003e (cache[id] = results[idx]));\\n    }\\n\\n    return ids.map((id) =\u003e cache[id]);\\n  }\\n\\n  return {\\n    load: async (id) =\u003e {\\n      const results = await loadMany([id]);\\n      return results[0];\\n    },\\n    loadMany,\\n  };\\n}\\n\\nmodule.exports = { make };\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Cache needs a function to retrieve multiple data by id (or in general by a key). It will check the data that is cached and request only the ids that are not found.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Implements the same contract as datasource.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"server.js\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's add this line to the server:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"const cache = require('./cache')\\nAnd replace this line:\\n\\nconst user = await resolver.getUserWithFriends(datasource, id, levels)\\nwith:\\n\\nconst user = await resolver.getUserWithFriends(cache.make(datasource.loadMany), id, levels)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Run\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's run again the server and test the previous request:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"http://localhost:3000/user-with-friends/1?levels=3\\n\"\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\nGET /users?ids=4\\nGET /users?ids=4\\nGET /users?ids=5\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We could reduce the number of requests from 9 to 5, which is pretty good. But, what a momentwhat happened here? Why are we requesting id=4 twice?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If we unnest the request flow based on how nodejs works (and how we implemented our resolver) this is what happened:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"1 - Load user 1 =\u003e GET /users?ids=1\\n2 - Load friends of 1: [2,3]=\u003e GET /users?ids=2,3\\n3.1. Load friends of 2: [1,3] =\u003e all cached\\n4.1. Load friends of 1 : [2,3] =\u003e all cached\\n4.2. Load friends of 3 : [1,2,4] =\u003e GET /users?ids=4\\n3.2. Load friends of 3: [1,2,4] =\u003e GET /users?ids=4\\n4.3. Load friends of 1: [2,3] =\u003e all cached\\n4.4. Load friends of 2: [1,3] =\u003e all cached\\n4.5. Load friends of 4: [3,5] =\u003e GET /users?ids=5\\nOn 3.1 we had all friends of user 2 cached. So the code was straight to 4.2, than ran in parallel with 3.2. Both were waiting for the same user (4) and therefore made the same requests twice.\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"So with our simple cache, we did not reduce the requests to the minimun we wanted.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For example, if we did:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"const users = await Promise.all(load(1), load(1));\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"There would be 2 requests before the cache has data for id=1.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's fix this and produce the ideal:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\nGET /users?ids=4\\nGET /users?ids=5\\n\"\n      })\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Dataloader\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Using nodejs \", _jsx(_components.code, {\n        children: \"process.nextTick(...)\"\n      }), \" we can postpone the execution of a given function to the end of the current event loop cycle. It is useful to run a given function after all variables are initialized for example.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"From nodejs documentation:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"By using process.nextTick() we guarantee that apiCall() always runs its callback after the rest of the user's code and before the event loop is allowed to proceed.\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Using it we can accumulate all the keys that are being requested during the same cycle (3.2 and 4.2 in the example above) and request them at the end. In the next cycle we would accumulate again the ones that were depending in the previous ones and so on.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This simple version of dataloader incorporates also code to accomplish the cache:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"function make(loadManyFn) {\\n  const cache = {};\\n  let pending = [];\\n  let scheduled = false;\\n  function scheduleSearch() {\\n    if (pending.length \u003e 0 \u0026\u0026 !scheduled) {\\n      scheduled = true;\\n      Promise.resolve().then(() =\u003e\\n        process.nextTick(async () =\u003e {\\n          await runSearch();\\n          scheduled = false;\\n        })\\n      );\\n    }\\n  }\\n\\n  async function runSearch() {\\n    const pendingCopy = pending.splice(0, pending.length);\\n    pending = [];\\n\\n    if (pendingCopy.length \u003e 0) {\\n      const results = await loadManyFn(pendingCopy.map((p) =\u003e p.id));\\n      pendingCopy.forEach(({ resolve }, idx) =\u003e resolve(results[idx]));\\n    }\\n  }\\n\\n  async function loadMany(ids) {\\n    const notCachedIds = ids.filter((id) =\u003e !cache[id]);\\n\\n    if (notCachedIds.length \u003e 0) {\\n      notCachedIds.map((id) =\u003e {\\n        cache[id] = new Promise((resolve) =\u003e {\\n          pending.push({ id, resolve });\\n        });\\n      });\\n\\n      scheduleSearch();\\n    }\\n\\n    return Promise.all(ids.map((id) =\u003e cache[id]));\\n  }\\n\\n  return {\\n    load: async (id) =\u003e {\\n      const results = await loadMany([id]);\\n      return results[0];\\n    },\\n    loadMany,\\n  };\\n}\\n\\nmodule.exports = { make };\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Ignoring the part of the cache, the important bits are:\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Accumulating requests\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"notCachedIds.map((id) =\u003e {\\n  cache[id] = new Promise((resolve) =\u003e {\\n    pending.push({ id, resolve });\\n  });\\n});\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We will add to the list of pending ids the ones that are not cached. We will keep the id and the resolve method, so we can resolve them afterwards with the right value. We cache the promise itself in the hashmap. This would allow us to cache also rejected promises for example. So we do not request over and over the same rejection. It is not used in this implementation, though.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Scheduling the request\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"function scheduleSearch() {\\n  if (pending.length \u003e 0 \u0026\u0026 !scheduled) {\\n    scheduled = true;\\n    Promise.resolve().then(() =\u003e\\n      process.nextTick(async () =\u003e {\\n        await runSearch();\\n        scheduled = false;\\n      })\\n    );\\n  }\\n}\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That is where the magic happens. This function is short but is the most important one: We schedule/delay the request to the end of all the promises declarations.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Executing the search\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-javascript\",\n        children: \"async function runSearch() {\\n  const pendingCopy = pending.splice(0, pending.length);\\n  pending = [];\\n\\n  if (pendingCopy.length \u003e 0) {\\n    const results = await loadManyFn(pendingCopy.map((p) =\u003e p.id));\\n    pendingCopy.forEach(({ resolve }, idx) =\u003e resolve(results[idx]));\\n  }\\n}\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Clone the ids (so they can be accumulated again after the search completes) and call the loadManyFn so we can resolve the promises we had pending. Remember the requirements of loadMany to return the data in the right order and all the elements ? This is where it is needed. We can reference the results by index and resolve the right pending promises.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let's run it!\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Execution\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Again the same request:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"http://localhost:3000/user-with-friends/1?levels=3\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"That produces the following output:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-text\",\n        children: \"GET /users?ids=1\\nGET /users?ids=2,3\\nGET /users?ids=4\\nGET /users?ids=5\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Exactly what we wanted.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Conclusion\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"Dataloader is a great package that should be in all developers toolbox. Specially the ones implementing Graphql or similar Apis.\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"The resolvers in this example could be optimized but sometimes our requests are on different files at different levels that depend on some conditions. With Dataloader we can keep our file structure and code readability without damaging our performance, both on response time to our client and on number of requests spawn within our mesh.\"\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Are you using Dataloader? Do you know any tool that accomplishes something similar? Do you now any other packages that in your opinion should be in all nodejs devs toolbox?\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}},"markdown":"# Understanding the Dataloader\n\nDataloader is one of the packages I find more useful and smart from the ones I have in my toolbox.\n\nI am going to set up a obvious naive example and follow the process to build a simple dataloader to understand its beauty and how useful it is.\n\n## About the project\n\nWe are going to create a view and api over a social network. Our users relations are:\n\n```text\nUser 1 friend of [ 2, 3 ]\nUser 2 friend of [ 1, 3 ]\nUser 3 friend of [ 1, 2, 4 ]\nUser 4 friend of [ 3, 5 ]\nUser 5 friend of [ 4 ]\n```\n\nThe view can show the relation between users and their friends. We can show N levels of their friendship. We are not goint to look much at it in this post.\n\nUsers data can be found here.\n\nThe only dependency will be express.\n\n## Initial Setup\n\n### datasource.js\n\nThe datasource allows us to retrieve one or multiple users by id. Contract is not random, it is already based on the real dataloader so there will be minimal changes over the course of the post. Data is defined in a file within the project. Code is pretty simple:\n\n```javascript\nconst users = require(\"./users.json\");\n\nconst getUsersFromFile = (ids) =\u003e\n  ids.map((id) =\u003e users.find((u) =\u003e u.id === id));\n\nconst sleep = (ms) =\u003e new Promise((resolve) =\u003e setTimeout(resolve, ms));\n\nasync function loadMany(ids) {\n  console.log(`GET /users?ids=${ids}`);\n\n  await sleep(100);\n  return getUsersFromFile(ids);\n}\n\nasync function load(id) {\n  const results = await loadMany([id]);\n  return results[0];\n}\n\nmodule.exports = {\n  load,\n  loadMany,\n};\n```\n\nThe only interesting method is loadMany. We will print the requests to the simulated service so we can check the console. There will be a delay to resolve the promise, so we can simulate better and understand why dataloader is so good.\n\nA very important requirement is that data needs to be returned to the caller in the right order and all elements need to be returned (same length of ids and results arrays). This will be clear when we put in place the dataloader.\n\n### resolver.js\n\nResolver will use the datasource received by parameter to load friendship data about users. It can receive the levels of friends we want to get, so it will use a recursive approach to load friends of friends until all levels are fetched.\n\n```javascript\nasync function getFriends(datasource, user, levels) {\n  if (levels == 0) {\n    return { id: user.id, name: user.name };\n  }\n\n  const friends = await datasource.loadMany(user.friends);\n\n  return {\n    ...user,\n    friends: await Promise.all(\n      friends.map((f) =\u003e getFriends(datasource, f, levels - 1))\n    ),\n  };\n}\n\nasync function getUserWithFriends(datasource, id, levels = 1) {\n  const user = await datasource.load(id);\n  return getFriends(datasource, user, levels);\n}\n\nmodule.exports = { getUserWithFriends };\n```\n\nIt uses a brute force approach on purpose. The code is simple but far away from being optimal. In one method it looks obvious, but sometimes, when we are building graphql or similar apis, or complex workflows we might be doing exactly this kind of brute force requests.\n\n### view.js\n\nNothing advanced. Just render users friends in a nested way.\n\n```javascript\nfunction render(user) {\n  return `\u003cdiv style=\"padding-left: 12px;background-color:#def\"\u003e ${user.name} ${\n    user.friends ? user.friends.map((u) =\u003e render(u)).join(\"\") : \"\"\n  } \u003c/div\u003e`;\n}\n\nmodule.exports = {\n  render,\n};\n```\n\n### server.js\n\n```javascript\nconst express = require(\"express\");\nconst PORT = 3000;\nconst app = express();\n\nconst datasource = require(\"./datasource\");\nconst resolver = require(\"./resolver\");\nconst view = require(\"./view\");\n\napp.get(`/user-with-friends/:id`, async (req, res) =\u003e {\n  const id = req.params.id;\n  const levels = req.query.levels || 1;\n\n  const user = await resolver.getUserWithFriends(datasource, id, levels);\n\n  res.send(view.render(user));\n});\n\napp.listen(PORT, () =\u003e console.log(`Fakebook listening to ${PORT}`));\n```\n\n## Run\n\n```shell\nnode index.js\n```\n\n## Test 1\n\nWe will render friends of user 1. Only 1 level:\n\n```text\nhttp://localhost:3000/user-with-friends/1\n```\n\nIf we check in our console we will find:\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\n```\n\nAll good. We requested user 1 and their friends 2 and 3.\n\n## Test 2\n\nLet's try by loading 3 levels:\n\n```text\nhttp://localhost:3000/user-with-friends/1?levels=3\n```\n\nThings are getting interesting here:\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\nGET /users?ids=1,3\nGET /users?ids=1,2,4\nGET /users?ids=2,3\nGET /users?ids=1,2,4\nGET /users?ids=2,3\nGET /users?ids=1,3\nGET /users?ids=3,5\n```\n\nWe are loading data for users 1,2,3,4,5 but we are doing 9 requests. We are requesting the same users again and again. We could easily improve the situation adding some sort of cache per request.\n\nCache per request\nWe are going to add a cache to the system. It will be empty at the start of each request, so we do not need to worry about expirations. The benefits will be:\n\nDo not request the same resource twice to the remote source during the same request.\nAs side effect, if we try to get the same resource twice during the same request, we will get the same data. So mutations of the resources in between a request will not provide incoherent results.\n\n### cache.js\n\nSimple cache implementation:\n\n```javascript\nfunction make(loadManyFn) {\n  const cache = {};\n\n  async function loadMany(ids) {\n    const notCachedIds = ids.filter((id) =\u003e !cache[id]);\n\n    if (notCachedIds.length \u003e 0) {\n      const results = await loadManyFn(notCachedIds);\n      notCachedIds.forEach((id, idx) =\u003e (cache[id] = results[idx]));\n    }\n\n    return ids.map((id) =\u003e cache[id]);\n  }\n\n  return {\n    load: async (id) =\u003e {\n      const results = await loadMany([id]);\n      return results[0];\n    },\n    loadMany,\n  };\n}\n\nmodule.exports = { make };\n```\n\nCache needs a function to retrieve multiple data by id (or in general by a key). It will check the data that is cached and request only the ids that are not found.\n\nImplements the same contract as datasource.\n\n### server.js\n\nLet's add this line to the server:\n\n```javascript\nconst cache = require('./cache')\nAnd replace this line:\n\nconst user = await resolver.getUserWithFriends(datasource, id, levels)\nwith:\n\nconst user = await resolver.getUserWithFriends(cache.make(datasource.loadMany), id, levels)\n```\n\n## Run\n\nLet's run again the server and test the previous request:\n\n```text\nhttp://localhost:3000/user-with-friends/1?levels=3\n```\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\nGET /users?ids=4\nGET /users?ids=4\nGET /users?ids=5\n```\n\nWe could reduce the number of requests from 9 to 5, which is pretty good. But, what a momentwhat happened here? Why are we requesting id=4 twice?\n\nIf we unnest the request flow based on how nodejs works (and how we implemented our resolver) this is what happened:\n\n```text\n1 - Load user 1 =\u003e GET /users?ids=1\n2 - Load friends of 1: [2,3]=\u003e GET /users?ids=2,3\n3.1. Load friends of 2: [1,3] =\u003e all cached\n4.1. Load friends of 1 : [2,3] =\u003e all cached\n4.2. Load friends of 3 : [1,2,4] =\u003e GET /users?ids=4\n3.2. Load friends of 3: [1,2,4] =\u003e GET /users?ids=4\n4.3. Load friends of 1: [2,3] =\u003e all cached\n4.4. Load friends of 2: [1,3] =\u003e all cached\n4.5. Load friends of 4: [3,5] =\u003e GET /users?ids=5\nOn 3.1 we had all friends of user 2 cached. So the code was straight to 4.2, than ran in parallel with 3.2. Both were waiting for the same user (4) and therefore made the same requests twice.\n```\n\nSo with our simple cache, we did not reduce the requests to the minimun we wanted.\n\nFor example, if we did:\n\n```javascript\nconst users = await Promise.all(load(1), load(1));\n```\n\nThere would be 2 requests before the cache has data for id=1.\n\nLet's fix this and produce the ideal:\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\nGET /users?ids=4\nGET /users?ids=5\n```\n\n## Dataloader\n\nUsing nodejs `process.nextTick(...)` we can postpone the execution of a given function to the end of the current event loop cycle. It is useful to run a given function after all variables are initialized for example.\n\nFrom nodejs documentation:\n\n```text\nBy using process.nextTick() we guarantee that apiCall() always runs its callback after the rest of the user's code and before the event loop is allowed to proceed.\n```\n\nUsing it we can accumulate all the keys that are being requested during the same cycle (3.2 and 4.2 in the example above) and request them at the end. In the next cycle we would accumulate again the ones that were depending in the previous ones and so on.\n\nThis simple version of dataloader incorporates also code to accomplish the cache:\n\n```javascript\nfunction make(loadManyFn) {\n  const cache = {};\n  let pending = [];\n  let scheduled = false;\n  function scheduleSearch() {\n    if (pending.length \u003e 0 \u0026\u0026 !scheduled) {\n      scheduled = true;\n      Promise.resolve().then(() =\u003e\n        process.nextTick(async () =\u003e {\n          await runSearch();\n          scheduled = false;\n        })\n      );\n    }\n  }\n\n  async function runSearch() {\n    const pendingCopy = pending.splice(0, pending.length);\n    pending = [];\n\n    if (pendingCopy.length \u003e 0) {\n      const results = await loadManyFn(pendingCopy.map((p) =\u003e p.id));\n      pendingCopy.forEach(({ resolve }, idx) =\u003e resolve(results[idx]));\n    }\n  }\n\n  async function loadMany(ids) {\n    const notCachedIds = ids.filter((id) =\u003e !cache[id]);\n\n    if (notCachedIds.length \u003e 0) {\n      notCachedIds.map((id) =\u003e {\n        cache[id] = new Promise((resolve) =\u003e {\n          pending.push({ id, resolve });\n        });\n      });\n\n      scheduleSearch();\n    }\n\n    return Promise.all(ids.map((id) =\u003e cache[id]));\n  }\n\n  return {\n    load: async (id) =\u003e {\n      const results = await loadMany([id]);\n      return results[0];\n    },\n    loadMany,\n  };\n}\n\nmodule.exports = { make };\n```\n\nIgnoring the part of the cache, the important bits are:\n\n### Accumulating requests\n\n```javascript\nnotCachedIds.map((id) =\u003e {\n  cache[id] = new Promise((resolve) =\u003e {\n    pending.push({ id, resolve });\n  });\n});\n```\n\nWe will add to the list of pending ids the ones that are not cached. We will keep the id and the resolve method, so we can resolve them afterwards with the right value. We cache the promise itself in the hashmap. This would allow us to cache also rejected promises for example. So we do not request over and over the same rejection. It is not used in this implementation, though.\n\n### Scheduling the request\n\n```javascript\nfunction scheduleSearch() {\n  if (pending.length \u003e 0 \u0026\u0026 !scheduled) {\n    scheduled = true;\n    Promise.resolve().then(() =\u003e\n      process.nextTick(async () =\u003e {\n        await runSearch();\n        scheduled = false;\n      })\n    );\n  }\n}\n```\n\nThat is where the magic happens. This function is short but is the most important one: We schedule/delay the request to the end of all the promises declarations.\n\n### Executing the search\n\n```javascript\nasync function runSearch() {\n  const pendingCopy = pending.splice(0, pending.length);\n  pending = [];\n\n  if (pendingCopy.length \u003e 0) {\n    const results = await loadManyFn(pendingCopy.map((p) =\u003e p.id));\n    pendingCopy.forEach(({ resolve }, idx) =\u003e resolve(results[idx]));\n  }\n}\n```\n\nClone the ids (so they can be accumulated again after the search completes) and call the loadManyFn so we can resolve the promises we had pending. Remember the requirements of loadMany to return the data in the right order and all the elements ? This is where it is needed. We can reference the results by index and resolve the right pending promises.\n\nLet's run it!\n\n## Execution\n\nAgain the same request:\n\n```text\nhttp://localhost:3000/user-with-friends/1?levels=3\n```\n\nThat produces the following output:\n\n```text\nGET /users?ids=1\nGET /users?ids=2,3\nGET /users?ids=4\nGET /users?ids=5\n```\n\nExactly what we wanted.\n\n## Conclusion\n\n- Dataloader is a great package that should be in all developers toolbox. Specially the ones implementing Graphql or similar Apis.\n\n- The resolvers in this example could be optimized but sometimes our requests are on different files at different levels that depend on some conditions. With Dataloader we can keep our file structure and code readability without damaging our performance, both on response time to our client and on number of requests spawn within our mesh.\n\nAre you using Dataloader? Do you know any tool that accomplishes something similar? Do you now any other packages that in your opinion should be in all nodejs devs toolbox?\n"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"data-loader"},"buildId":"AWYFh2Cu81pZ9PtCaFAIO","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>